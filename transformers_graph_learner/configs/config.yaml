defaults:
  - override hydra/launcher: joblib

seed: 2

wandb:
  project: "transformer-graph-learner"
  entity: "L65_Project"
  group: "test_arch_change"

dataset:
  num_graphs: 300
  d_p: 10
  d_e: 1
  node_id_encode: "one-hot"
  in_feat_dim: 1
  split: 0.8
  n_nodes_range: [8, 8]


training:
  epoch: &num_epochs 300
  num_epochs: *num_epochs
  batch_size: 128
  lr: 2e-4
  weight_decay: 0.1
  device: "cuda"  # set to "cpu" if you don't want to use CUDA
  save_every: 50

model:
  d_model: 512
  nhead: 1
  num_layers: 5
  dropout: 0.1
  input_dropout: 0.1

scheduler:
  warmup_steps: 100  # Check the num_epochs and adjust this value accordingly


paths:
  models: "models"
