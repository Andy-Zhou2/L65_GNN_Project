defaults:
  - override hydra/launcher: joblib

seed: 2

wandb:
  project: "transformer-graph-learner"
  entity: "L65_Project"
  group: "test"

dataset:
  num_graphs: 1000
  d_p: 16
  d_e: 1
  node_id_encode: "orf"
  in_feat_dim: 1
  split: 0.8
  n_nodes_range: [6, 6]
  eccentricity: 4


training:
  epoch: &num_epochs 300
  num_epochs: *num_epochs
  batch_size: 128
  lr: 5e-5
  weight_decay: 0.1
  device: "cuda"  # set to "cpu" if you don't want to use CUDA
  save_every: 50
  early_stopping:
    enabled: true
    patience: 30
    verbose: false
    min_delta: 0

model:
  d_model: 512
  nhead: 1
  num_layers: 5
  dropout: 0.1
  input_dropout: 0.1

scheduler:
  warmup_steps: null  # Check the num_epochs and adjust this value accordingly


paths:
  models: "models"
