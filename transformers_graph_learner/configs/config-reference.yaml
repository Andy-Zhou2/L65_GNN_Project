defaults:
  - override hydra/launcher: joblib

seed: 2

wandb:
  project: "transformer-graph-learner"
  entity: "L65_Project"
  group: "test"

dataset:
  use_existing: false
  dataset_path: "dataset"
  num_graphs: 40_000
  d_p: 32
  d_e: 1
  node_id_encode: "orf"
  in_feat_dim: 1
  split: 0.8
  n_nodes_range: [128, 128]
  eccentricity: 8  # null for no restriction

  m: 1
  p: 0.15
  q: 0


training:
  epoch: &num_epochs 30000
  num_epochs: *num_epochs
  batch_size: 128
  lr: 5e-5
  weight_decay: 0.1
  device: "cuda"  # set to "cpu" if you don't want to use CUDA
  save_every: 50
  early_stopping:
    enabled: false
    patience: 30
    verbose: false
    min_delta: 0

model:
  d_model: 512
  nhead: 16
  num_layers: 5
  dropout: 0.1
  input_dropout: 0.1

scheduler:
  warmup_steps: null  # Check the num_epochs and adjust this value accordingly


paths:
  models: "models"
